{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing packages\n"
     ]
    }
   ],
   "source": [
    "print \"Importing packages\"\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as learn\n",
    "import xgboost\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third attempt at the DonorsChoose Dataset. Very basic stacking model.\n",
    "Anisotropic's notebook on Stacking\\ensembling was really useful for creating this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/IPython/core/interactiveshell.py:2718: DtypeWarning: Columns (11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#reading data\n",
    "\n",
    "train= pd.read_csv(\"/home/souravg/train.csv\")\n",
    "\n",
    "test=pd.read_csv(\"/home/souravg/test.csv\") \n",
    "\n",
    "resource= pd.read_csv(\"/home/souravg/resources.csv\")\n",
    "\n",
    "#print train.head(7)\n",
    "\n",
    "#print resource.head(7)\n",
    "\n",
    "\n",
    "joined= pd.merge(train,resource,how='inner',on='id',sort=False,)\n",
    "\n",
    "joined_test=pd.merge(test,resource,how='inner',on='id',sort=False,)\n",
    "\n",
    "\n",
    "#print joined.columns\n",
    "\n",
    "#print joined.head(5)\n",
    "\n",
    "#train.school_state.astype(\"category\")\n",
    "\n",
    "#train.project_grade_category.astype(\"category\")\n",
    "\n",
    "#train.project_subject_categories.astype(\"category\")\n",
    "\n",
    "#train.project_subject_subcategories.astype(\"category\")\n",
    "\n",
    "print'--------------------------------------------------'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------\n"
     ]
    }
   ],
   "source": [
    "joined['Total_sum']= joined.quantity*joined.price\n",
    "joined_test['Total_sum']= joined_test.quantity*joined_test.price\n",
    "#print joined.head(3)\n",
    "\n",
    "print '-------------------------------'\n",
    "\n",
    "#print joined_test.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "sumdf= joined.groupby('id',as_index=False).agg({'Total_sum':'sum'})\n",
    "\n",
    "sumdf_test=joined_test.groupby('id',as_index=False).agg({'Total_sum':'sum'})\n",
    "\n",
    "#print sumdf.head(3)\n",
    "print '-----------------------'\n",
    "#print sumdf_test.head(3)\n",
    "\n",
    "#print joined.Total_sum.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "final_train= pd.merge(train,sumdf,on='id',how='inner',sort=False,)\n",
    "final_test=pd.merge(test,sumdf_test,on='id',how='inner',sort=False,)\n",
    "\n",
    "#print final_train.head(3)\n",
    "print '-------------------'\n",
    "#print final_test.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell above read the train data, converted appropriate parameters to categorical type & did some group by counts. From the results it seems like California, New York, Texas & Florida have the largest number of projects.\n",
    "Grades PreK-2 had the most number of projects, & the number of projects decrease monotonically with increasing age of students. Grades 9-12 have the fewest number of projects. I must say that this came as a surprise, I would hae thought seniors would need more funding.\n",
    "There seems to be the following project categories:-\n",
    "\n",
    "Applied Learning\n",
    "Health & Sports\n",
    "History & Civics\n",
    "Math & Science\n",
    "Music & The Arts\n",
    "Special Needs\n",
    "Warmth, Care & Hunger\n",
    "\n",
    "But the majority of projects are tagged with multiple categories, hence there are lot more different project categories in the data (combinations of the base categories).\n",
    "\n",
    "Math & Science, Literacy & Language & Health & Sport seem to be leaders in terms of project count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "Index([u'school_state', u'project_grade_category',\n",
      "       u'project_subject_categories'],\n",
      "      dtype='object')\n",
      "&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&\n",
      "copy count    260115.000000\n",
      "mean         22.977856\n",
      "std          14.924920\n",
      "min           0.000000\n",
      "25%           9.000000\n",
      "50%          22.000000\n",
      "75%          36.000000\n",
      "max          50.000000\n",
      "Name: school_state, dtype: float64\n",
      "copy count    260115.000000\n",
      "mean          1.571117\n",
      "std           1.316890\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%           2.000000\n",
      "75%           3.000000\n",
      "max           3.000000\n",
      "Name: project_grade_category, dtype: float64\n",
      "copy count    260115.000000\n",
      "mean         25.046414\n",
      "std          11.742591\n",
      "min           0.000000\n",
      "25%          24.000000\n",
      "50%          28.000000\n",
      "75%          32.000000\n",
      "max          50.000000\n",
      "Name: project_subject_categories, dtype: float64\n",
      "[[[[[[[[[[[[[[[[[]]]]]]]]]]]]]]]]]\n",
      "----------------------------\n",
      "   school_state  project_grade_category  project_subject_categories  \\\n",
      "0            33                       3                          24   \n",
      "1            10                       0                          42   \n",
      "\n",
      "   teacher_number_of_previously_posted_projects  Total_sum  \n",
      "0                                            26     899.94  \n",
      "1                                             1     400.00  \n",
      "--------------------------------\n",
      "   school_state  project_grade_category  project_subject_categories  \\\n",
      "0             4                       3                          40   \n",
      "1            40                       0                          28   \n",
      "\n",
      "   teacher_number_of_previously_posted_projects  Total_sum  \n",
      "0                                             2     149.00  \n",
      "1                                             1     238.34  \n",
      "***************************************\n"
     ]
    }
   ],
   "source": [
    "train=final_train\n",
    "test=final_test\n",
    "\n",
    "ftest=test.drop([u'id', u'teacher_id', u'teacher_prefix',u'project_title', u'project_essay_1', u'project_essay_2',\n",
    "       u'project_essay_3', u'project_essay_4', u'project_resource_summary','project_submitted_datetime','project_subject_subcategories'],1)\n",
    "\n",
    "ftrain=train.drop([u'id', u'teacher_id', u'teacher_prefix',u'project_title', u'project_essay_1', u'project_essay_2',\n",
    "       u'project_essay_3', u'project_essay_4', u'project_resource_summary','project_submitted_datetime','project_subject_subcategories'],1)\n",
    "\n",
    "target=ftrain.project_is_approved\n",
    "\n",
    "ftrain=ftrain.drop(['project_is_approved'],1)\n",
    "\n",
    "print '----------------------------------'\n",
    "\n",
    "copy=pd.DataFrame(pd.concat([ftrain,ftest]))\n",
    "\n",
    "copy[\"school_state\"]=copy[\"school_state\"].astype('category')\n",
    "copy[\"project_grade_category\"]=copy[\"project_grade_category\"].astype('category')\n",
    "copy[\"project_subject_categories\"]=copy[\"project_subject_categories\"].astype('category')\n",
    "print '&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&'\n",
    "cat_columns = copy.select_dtypes(['category']).columns\n",
    "\n",
    "print cat_columns\n",
    "\n",
    "copy[cat_columns] = copy[cat_columns].apply(lambda x: x.cat.codes)\n",
    "\n",
    "#copy['school_state']=copy['school_state'].cat.codes\n",
    "#copy['project_grade_category']=copy['project_grade_category'].cat.codes\n",
    "#copy['project_subject_categories']=copy['project_subject_categories'].cat.codes\n",
    "#copy['project_subject_subcategories']=copy['project_subject_subcategories'].cat.codes\n",
    "print '&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&'\n",
    "print 'copy',copy[\"school_state\"].describe()\n",
    "print 'copy',copy[\"project_grade_category\"].describe()\n",
    "print 'copy',copy[\"project_subject_categories\"].describe()\n",
    "print '[[[[[[[[[[[[[[[[[]]]]]]]]]]]]]]]]]'\n",
    "\n",
    "#copy=copy.drop([u'school_state', u'project_grade_category', u'project_subject_categories',u'project_subject_subcategories'],1)\n",
    "\n",
    "ftrain= copy[0:182080]\n",
    "ftest= copy[182080:]\n",
    "\n",
    "print '----------------------------'\n",
    "\n",
    "print ftrain.head(2)\n",
    "print '--------------------------------'\n",
    "print ftest.head(2)\n",
    "\n",
    "\n",
    "#print target.head(5)\n",
    "\n",
    "#ftrain=pd.get_dummies(ftrain,prefix=['state','grade','categories','subcategories'])\n",
    "\n",
    "#ftest=pd.get_dummies(ftest,prefix=['state','grade','categories','subcategories'])\n",
    "\n",
    "print '***************************************'\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*****************************************\n",
      "Hola\n",
      "Feature importance from random forest=\n",
      "[ 0.01363058  0.00931885  0.15464824  0.61235736  0.21004498]\n",
      "finito\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print '*****************************************'\n",
    "\n",
    "\n",
    "#print '========================================== Normalization of project count & total sum'\n",
    "\n",
    "#projectcount_mean=ftrain['teacher_number_of_previously_posted_projects'].mean()\n",
    "#projectcount_sd=ftrain['teacher_number_of_previously_posted_projects'].std()\n",
    "\n",
    "#totalsum_mean=ftrain['Total_sum'].mean()\n",
    "#totalsum_sd=ftrain['Total_sum'].std()\n",
    "\n",
    "#print projectcount_mean,' ',projectcount_sd\n",
    "\n",
    "#ftrain['Total_sum']=(ftrain['Total_sum']-totalsum_mean)/totalsum_sd\n",
    "#ftrain['teacher_number_of_previously_posted_projects']= (ftrain['teacher_number_of_previously_posted_projects']-projectcount_mean)/projectcount_sd\n",
    "\n",
    "#ftest['Total_sum']=(ftest['Total_sum']-totalsum_mean)/totalsum_sd\n",
    "#ftest['teacher_number_of_previously_posted_projects']= (ftest['teacher_number_of_previously_posted_projects']-projectcount_mean)/projectcount_sd\n",
    "\n",
    "\n",
    "#print '-------------------------------- Normalization done'\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn import tree\n",
    "from sklearn import ensemble\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "abclf= ensemble.AdaBoostClassifier(n_estimators=1000,)\n",
    "rfclf= ensemble.RandomForestClassifier(n_estimators=1000,criterion='entropy',max_depth=5,warm_start=True,)\n",
    "gbclf= ensemble.GradientBoostingClassifier(n_estimators=1000,max_depth=4,min_samples_split=4,subsample=.3)\n",
    "\n",
    "clf= ensemble.RandomForestClassifier(n_estimators=500,criterion='entropy',max_depth=3,warm_start=True,)\n",
    "#clf = AdaBoostClassifier(n_estimators=500, learning_rate= 0.4)\n",
    "#clf = MLPClassifier(solver='adam', alpha=1e-5,hidden_layer_sizes=(200, 100), random_state=1,max_iter=1000)\n",
    "print \"Hola\"\n",
    "\n",
    "\n",
    "\n",
    "clf.fit(ftrain,target)\n",
    "\n",
    "\n",
    "#abclf.fit(ftrain, target)\n",
    "#rfclf.fit(ftrain, target)\n",
    "#gbclf.fit(ftrain, target)\n",
    "\n",
    "#print 'Feature importance from adaboost='\n",
    "#print abclf.feature_importances_\n",
    "\n",
    "print 'Feature importance from random forest='\n",
    "print clf.feature_importances_\n",
    "\n",
    "#print 'Feature importance from gradient boosting='\n",
    "#print gbclf.feature_importances_\n",
    "\n",
    "#tabresult=abclf.predict_proba(ftrain)\n",
    "#trfresult=rfclf.predict_proba(ftrain)\n",
    "#tgbresult=gbclf.predict_proba(ftrain)\n",
    "\n",
    "\n",
    "#abresult=abclf.predict_proba(ftest)\n",
    "#rfresult=rfclf.predict_proba(ftest)\n",
    "#gbresult=gbclf.predict_proba(ftest)\n",
    "\n",
    "print \"finito\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78035, 2)\n",
      "         id  project_is_approved\n",
      "0   p233245             0.837631\n",
      "1   p096795             0.855831\n",
      "2   p236235             0.829173\n",
      "3   p233680             0.851656\n",
      "4   p171879             0.826077\n",
      "5   p016071             0.841211\n",
      "6   p099906             0.863504\n",
      "7   p200236             0.847926\n",
      "8   p129452             0.880722\n",
      "9   p186652             0.847473\n",
      "10  p257992             0.855495\n",
      "11  p055177             0.835415\n",
      "12  p069502             0.849052\n",
      "13  p099455             0.856198\n",
      "14  p226195             0.869366\n",
      "15  p048432             0.885633\n",
      "16  p028074             0.853984\n",
      "17  p188220             0.818295\n",
      "18  p213507             0.851997\n",
      "19  p006068             0.863422\n",
      "20  p124112             0.850494\n",
      "21  p190450             0.832231\n",
      "22  p180156             0.820369\n",
      "23  p025868             0.834366\n",
      "24  p134875             0.820173\n",
      "25  p169259             0.833154\n",
      "26  p124445             0.850317\n",
      "27  p090153             0.903948\n",
      "28  p086796             0.854164\n",
      "29  p101412             0.897229\n"
     ]
    }
   ],
   "source": [
    "\n",
    "result=clf.predict_proba(ftest)\n",
    "\n",
    "r_df=pd.DataFrame(dict(id=test.id,project_is_approved=result[:,1]))\n",
    "\n",
    "print r_df.shape\n",
    "print r_df.head(30)\n",
    "#print rfclf.feature_importances_\n",
    "\n",
    "\n",
    "r_df.to_csv('/home/souravg/output5.2.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.16478707  0.83521293]\n",
      " [ 0.13464939  0.86535061]\n",
      " [ 0.18761641  0.81238359]\n",
      " [ 0.14355027  0.85644973]\n",
      " [ 0.17657868  0.82342132]\n",
      " [ 0.15248022  0.84751978]\n",
      " [ 0.13040103  0.86959897]\n",
      " [ 0.14690793  0.85309207]\n",
      " [ 0.10957476  0.89042524]\n",
      " [ 0.14672544  0.85327456]\n",
      " [ 0.13865819  0.86134181]\n",
      " [ 0.15728328  0.84271672]\n",
      " [ 0.16674882  0.83325118]\n",
      " [ 0.13409432  0.86590568]\n",
      " [ 0.12280192  0.87719808]\n",
      " [ 0.11945113  0.88054887]\n",
      " [ 0.14228784  0.85771216]\n",
      " [ 0.19036895  0.80963105]\n",
      " [ 0.14258076  0.85741924]\n",
      " [ 0.13383068  0.86616932]\n",
      " [ 0.17531093  0.82468907]\n",
      " [ 0.16300933  0.83699067]\n",
      " [ 0.17815078  0.82184922]\n",
      " [ 0.17188554  0.82811446]\n",
      " [ 0.1812131   0.8187869 ]\n",
      " [ 0.17091193  0.82908807]\n",
      " [ 0.16154056  0.83845944]\n",
      " [ 0.08719656  0.91280344]\n",
      " [ 0.14170426  0.85829574]\n",
      " [ 0.09523673  0.90476327]]\n",
      "0     p233245\n",
      "1     p096795\n",
      "2     p236235\n",
      "3     p233680\n",
      "4     p171879\n",
      "5     p016071\n",
      "6     p099906\n",
      "7     p200236\n",
      "8     p129452\n",
      "9     p186652\n",
      "10    p257992\n",
      "11    p055177\n",
      "12    p069502\n",
      "13    p099455\n",
      "14    p226195\n",
      "15    p048432\n",
      "16    p028074\n",
      "17    p188220\n",
      "18    p213507\n",
      "19    p006068\n",
      "20    p124112\n",
      "21    p190450\n",
      "22    p180156\n",
      "23    p025868\n",
      "24    p134875\n",
      "25    p169259\n",
      "26    p124445\n",
      "27    p090153\n",
      "28    p086796\n",
      "29    p101412\n",
      "Name: id, dtype: object\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
